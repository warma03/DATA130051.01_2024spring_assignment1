def train(X, y, hidden_size, reg_lambda, learning_rate, num_epochs, batch_size, val_images, val_labels):

    train_loss_history = []
    val_loss_history = []
    val_accuracy_history = []
    
    input_size = X.shape[1]
    output_size = 10

    model = NeuralNetwork(input_size, hidden_size, output_size)

    num_batches = len(X) // batch_size

    for epoch in range(num_epochs):
        for batch in range(num_batches):
            start = batch * batch_size
            end = start + batch_size
            X_batch = X[start:end]
            y_batch = y[start:end]

            model.forward(X_batch)
            model.backward(X_batch, y_batch, reg_lambda)

        model.forward(X)
        train_loss = -np.mean(np.log(model.probs[range(len(X)), np.argmax(y, axis=1)]))
        train_loss_history.append(train_loss)


        model.forward(val_images)
        val_loss = -np.mean(np.log(model.probs[range(len(val_images)), np.argmax(val_labels, axis=1)]))
        val_loss_history.append(val_loss)
        val_predictions = model.predict(val_images)
        val_accuracy = np.mean(val_predictions == np.argmax(val_labels, axis=1))
        val_accuracy_history.append(val_accuracy)
        
        if (epoch + 1) % 10 == 0:
            accuracy = np.mean(np.argmax(y, axis=1) == model.predict(X))
            print(f'Epoch: {epoch+1}, Accuracy: {accuracy}')

    epochs = range(1, num_epochs+1)
    plt.figure(figsize=(10, 5))
    plt.plot(epochs, train_loss_history, label='Training Loss')
    plt.plot(epochs, val_loss_history, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.show()


    plt.figure(figsize=(10, 5))
    plt.plot(epochs, val_accuracy_history, label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Validation Accuracy')
    plt.legend()
    plt.show()
    
    return model
